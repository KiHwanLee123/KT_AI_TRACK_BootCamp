{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "W8-5lC4mfbwT",
        "u2YESAa5fc4M"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **저시력자를 위한 원화 화폐 분류**\n",
        "---\n",
        "- 본 과제는 UltraLytics YOLO v5 모델 사용을 권장합니다.\n",
        "    - 본 파일의 목차는 UltraLytics YOLO v5에 맞게 작성되어 있습니다.\n",
        "    - 다른 모델을 찾아서 사용하셔도 좋습니다.\n",
        "    - 산출물이 잘 나오면 됩니다 : )\n",
        "---"
      ],
      "metadata": {
        "id": "XT7PRhnMf-kI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.미션\n",
        "---\n",
        "- **과제 수행 목표**\n",
        "    - 본 과제는 Object Detection 문제입니다.\n",
        "    - Object Detection 문제로 접근하기 위해 **데이터셋 전처리**를 하셔야 합니다.\n",
        "    - 데이터셋 : money_dataset.zip\n",
        "        1. 데이터셋은 압축 파일로 제공됩니다.\n",
        "        2. 압축 파일 안에는 화폐마다 폴더가 개별적으로 존재합니다.\n",
        "        3. 폴더 안에는 화폐 이미지와 화폐 정보가 담긴 json 파일이 있습니다.\n",
        "    - 여러분이 직접 촬영한 화폐 사진들을 탐지 과정에서 이용 해보세요.\n",
        "    - 이미지에 화폐 하나만 나오게 촬영하는 것은 지양해주세요.\n",
        "    - 다양한 방법으로 화폐를 촬영하고 결과를 확인해보세요.\n",
        "        - ex 1) 화폐의 모든 종류를 한 이미지에 나오게 촬영\n",
        "        - ex 2) 여러 화폐를 겹치게 하여 촬영\n",
        "---\n",
        "- **Key Point**\n",
        "    1. 모델에 맞는 폴더 구조 확인\n",
        "    2. 이미지 축소 비율에 맞춰 좌표값 변경\n",
        "        - 좌표를 이미지 리사이즈한 비율로 변경\n",
        "    3. 모델에 맞는 정보 추출/형식 변경\n",
        "        - json 파일에서 정보 추출 및 모델 형식에 맞게 변경\n",
        "    4. 화폐당 하나의 클래스로 변경\n",
        "        - 총 8개 클래스\n",
        "    5. 모델 선택 필요\n",
        "---"
      ],
      "metadata": {
        "id": "47D2vGDYdCOz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.환경설정"
      ],
      "metadata": {
        "id": "aZon1K-Ag9be"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (1) 구글 드라이브 연동\n",
        "---\n",
        "- 아래의 코드 셀을 반드시 실행시켜야 합니다.\n",
        "---"
      ],
      "metadata": {
        "id": "CMgnHN9ZBF05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "xCplyiojBFwh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03feb9b7-7562-40dd-8629-8855cb1eb04c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (2) 데이터셋 불러오기\n",
        "---\n",
        "- **세부요구사항**\n",
        "    - 데이터셋 파일의 압축을 해제하세요.\n",
        "---\n",
        "- 예제 코드에서는 zipfile 모듈을 이용하였습니다.\n",
        "    - [zipfile document](https://docs.python.org/3/library/zipfile.html#zipfile-objects)\n",
        "    - 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n",
        "---"
      ],
      "metadata": {
        "id": "J8vjv0acBAV4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bkSa5ejf8LMe"
      },
      "outputs": [],
      "source": [
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# zip 파일까지의 경로\n",
        "dataset_path = '/content/drive/MyDrive/ktaivle_mp3th_2/Datasets_money/money_dataset.zip'"
      ],
      "metadata": {
        "id": "XD1iuKt0PLVN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 압축 파일 경로 : 유저별로 상이할 수 있음\n",
        "money_data = zipfile.ZipFile(dataset_path)"
      ],
      "metadata": {
        "id": "N4cdpkRv86QQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MyDrive 경로 내에 압축을을 해제할 경우 코드를 다시 실행 했을 때 오류가 납니다. 되도록이면 content 하위 경로에 폴더를 만들어 저장하도록 합시다.\n",
        "\n",
        "인터넷 연결이 정상적인 경우 ZipFile()로 충분히 빠른 시간내에 압축 해제가 가능합니다.\n",
        "\n",
        "게다가, 현재 colab pro를 사용하고 있기 때문에 고용량 RAM을 사용해 자리를 비워도 코랩이 데이터를 기억하도록 할 수 있습니다.\n"
      ],
      "metadata": {
        "id": "G6pIrpzdp-Ew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 압축 해제\n",
        "money_data.extractall('/content/Datasets_money/')"
      ],
      "metadata": {
        "id": "TDAyDRLT9hZS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 압축 해제된 데이터셋이 들어있는경로\n",
        "data_path = '/content/Datasets_money/'"
      ],
      "metadata": {
        "id": "yt_ZJ5IDPih5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.데이터 전처리"
      ],
      "metadata": {
        "id": "QyEd-WNIhoSc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (1) 폴더 구조 생성 및 파일 이동\n",
        "---\n",
        "- **세부요구사항**\n",
        "    -  모델에서 요구하는 폴더 구조를 만들어야 합니다.\n",
        "        - Hint : Image와 Label을 구분하는 폴더를 만들어 주세요\n",
        "---\n",
        "- 예제 코드에서는 glob, shutil 모듈을 이용하였습니다.\n",
        "    - [glob document](https://docs.python.org/3/library/glob.html) | [shutil document](https://docs.python.org/3/library/shutil.html)\n",
        "    - 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n",
        "---"
      ],
      "metadata": {
        "id": "P81d6utx-3LY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.폴더 구조 만들기\n",
        "try:\n",
        "    !mkdir /content/Dataset/\n",
        "except:\n",
        "    pass\n",
        "try:\n",
        "    !mkdir /content/Dataset/images;\n",
        "    !mkdir /content/Dataset/images/train; mkdir /content/Dataset/images/val\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    !mkdir /content/Dataset/labels;\n",
        "    !mkdir /content/Dataset/labels/train; mkdir /content/Dataset/labels/val\n",
        "except:\n",
        "    pass"
      ],
      "metadata": {
        "id": "YBqCJU5z_UI8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 경로를 미리 지정해둡시다다\n",
        "train_img_path = '/content/Dataset/images/train/'\n",
        "valid_img_path = '/content/Dataset/images/val'\n",
        "\n",
        "train_lab_path = '/content/Dataset/labels/train'\n",
        "valid_lab_path = '/content/Dataset/labels/val'"
      ],
      "metadata": {
        "id": "JJay40W3u7ia"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, shutil\n",
        "import random"
      ],
      "metadata": {
        "id": "UuchlNA_DftJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Dataset metadata 입력\n",
        "won_list = ['10', '50', '100', '500', '1000', '5000', '10000', '50000']"
      ],
      "metadata": {
        "id": "Q3lnYcLS_UOy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "- 데이터를 Training set | Validation set으로 분할하세요.\n",
        "    - 예시 : Training과 Validation은 8:2로 분리\n",
        "- Hint : 이미지 데이터는 /images에, JSON 데이터는 /labels에 넣어주세요\n",
        "    - 예시 : /dataset/images/train, /dataset/labels/train\n",
        "    - 예제 코드에서는 glob, shutil 모듈을 이용하였습니다.\n",
        "    - [glob document](https://docs.python.org/3/library/glob.html) | [shutil document](https://docs.python.org/3/library/shutil.html)\n",
        "\n",
        "    ※ 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n",
        "    \n",
        "---"
      ],
      "metadata": {
        "id": "ihJgeqXJG1Ml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "딕셔너리를 이용해 각 클래스(돈의 종류)별로 확장자를 제외한 파일 이름을 담은 리스트를 생성하겠습니다.\n",
        "- tip\n",
        "    - glob.glob()은 하위 폴더 및 파일들의 전체 경로를 담은 리스트를 반환하고, os.listdir()은 하위 폴더 및 파일들의 이름만 반환하므로 편의에 맞게 잘 사용하도록 합시다."
      ],
      "metadata": {
        "id": "ta7_px6Jr9MX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "won_data_dic = dict()"
      ],
      "metadata": {
        "id": "eA2bTAo8Y68H"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "각 폴더들을 보면 이미지 파일 바로뒤에 json파일이 따라옵니다.\n",
        "\n",
        "저는 파일 이름만 필요하기에 2칸씩 띄어 세어서 연산량을 줄이도록 하겠습니다."
      ],
      "metadata": {
        "id": "p1YaukS4s6hx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for won in won_list:\n",
        "    file_pathes = glob.glob(f'{data_path}{won}/*')\n",
        "    won_data_dic[won] = []\n",
        "    # 리스트 내의 요소들을 k개씩 띄어 세기 list[::k]\n",
        "    for file_path in file_pathes[::2]:\n",
        "        filename, ext = file_path.split('.')\n",
        "        won_data_dic[won].append(filename)"
      ],
      "metadata": {
        "id": "Mz-BdjBuU_Sj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "방금 우리가 딕셔너리에 담았던, 클래스이름을 key값으로 하는 파일 이름 리스트 속에 있는 요소들의 숫자(파일 이름 수)와 실제 각 클래스별 파일 이름 수를 비교해보도록 하겠습니다."
      ],
      "metadata": {
        "id": "1nrX04YctcMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for won in won_list:\n",
        "    file_pathes = glob.glob(f'{data_path}{won}/*')\n",
        "    print(len(file_pathes)// 2) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tMSVuX2Zzhv",
        "outputId": "cc3e4f81-a973-4c6d-d171-6f3cd9b0b180"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "436\n",
            "440\n",
            "440\n",
            "440\n",
            "858\n",
            "867\n",
            "867\n",
            "870\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for key in won_list:\n",
        "    print(len(won_data_dic[key]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QF3R6FaOZjqa",
        "outputId": "4899c21a-0730-487b-f5d6-e7f8864a9141"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "436\n",
            "440\n",
            "440\n",
            "440\n",
            "858\n",
            "867\n",
            "867\n",
            "870\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 코드는 사실 안좋은 예시였답니다 ㅎㅎ.\n",
        "\n",
        "파이썬이 저한테 **'너가 준 파일이름 이미 옮겨놨는데 왜 또 줌?'**이라고 하면서 오류를 뱉어주네요.\n",
        "\n",
        "아마, 제가 위에서 **'각 폴더들을 보면 이미지 파일 바로뒤에 json파일이 따라옵니다'** 라고 한 부분이 틀렸던 것 같네요 순서가 짬뽕인 친구들이 있나봅니다.\n",
        "\n",
        "이번엔 /*jpg를 이용해 파일 경로의 끝이 jpg로 끝나는(확장자가 .jpg)인 파일만 뽑아서 다시 해보도록 하겠습니다."
      ],
      "metadata": {
        "id": "Gp0mzKZrym_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for won in won_list:\n",
        "    file_pathes = glob.glob(f'{data_path}{won}/*jpg')\n",
        "    won_data_dic[won] = []\n",
        "    # 리스트 내의 요소들을 k개씩 띄어 세기 list[::k]\n",
        "    for file_path in file_pathes:\n",
        "        filename, ext = file_path.split('.')\n",
        "        won_data_dic[won].append(filename)"
      ],
      "metadata": {
        "id": "eSTsKPpkyen2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('현재 데이터셋에 존재하는 파일 이름 개수')\n",
        "for won in won_list:\n",
        "    file_pathes = glob.glob(f'{data_path}{won}/*')\n",
        "    print(len(file_pathes)// 2) \n",
        "print('딕셔너리 속 파일 이름 개수')\n",
        "for key in won_list:\n",
        "    print(len(won_data_dic[key]))    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IE2Fcb8WaqP5",
        "outputId": "1af7eed5-c738-42e6-a791-85b4c6cce2b1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 데이터셋에 존재하는 파일 이름 개수\n",
            "436\n",
            "440\n",
            "440\n",
            "440\n",
            "858\n",
            "867\n",
            "867\n",
            "870\n",
            "딕셔너리 속 파일 이름 개수\n",
            "436\n",
            "440\n",
            "440\n",
            "440\n",
            "858\n",
            "867\n",
            "867\n",
            "870\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image 파일과 Label 파일을 동시에 이동시키기\n"
      ],
      "metadata": {
        "id": "EF75Bu0awCXP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 각 클래스별 파일이름 리스트를 shuffle로 섞는다. \n",
        "2. 파일이름 리스트의 길이를 구하고, validation 데이터의 크기 비율을 그 길이에 곱해서 val 폴더로 들어갈 마지막 index값을 구한다.\n",
        "3. enumerate를 이용해 각 리스트 속 파일 이름의 index 정보를 함께 얻어내 각 파일이 train 폴더로 갈지 val 폴더로 갈지 정한다.\n",
        "    - 이때, 폴더 이름에 확장자(.jpg, .json)를 붙여서 두개의 폴더가 가야할 곳으로 한번에 이동하도록 한다.\n",
        "4. 1~3을 모든 클래스에 대해서 각각 실행한다."
      ],
      "metadata": {
        "id": "ZaQ4VMGYvEEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "won_data_dic['10'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HK7wsrWKa8Yt",
        "outputId": "77aa3ab5-a5ce-4598-ecdb-1651d8d3c37c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Datasets_money/10/10_631_9'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(2023)\n",
        "valid_size = 0.2\n",
        "for key in won_list:\n",
        "    shuffle_lst = won_data_dic[key].copy()\n",
        "    random.shuffle(shuffle_lst)\n",
        "    lst_num = len(shuffle_lst)\n",
        "    last_val_idx = int(lst_num * valid_size)\n",
        "    for idx, filename in enumerate(shuffle_lst):\n",
        "        # train으로 이동\n",
        "        if idx > last_val_idx:\n",
        "            # image - jpg\n",
        "            shutil.move(filename + '.jpg', train_img_path)\n",
        "            # label - json\n",
        "            shutil.move(filename + '.json', train_lab_path)\n",
        "        # val로\n",
        "        else:\n",
        "            # image - jpg\n",
        "            shutil.move(filename + '.jpg', valid_img_path)\n",
        "            # label - json\n",
        "            shutil.move(filename + '.json', valid_lab_path)"
      ],
      "metadata": {
        "id": "gWMhqDWOac6d"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(glob.glob('/content/Dataset/images/train/*')),\n",
        "len(glob.glob('/content/Dataset/images/val/*')),\n",
        "\n",
        "len(glob.glob('/content/Dataset/labels/train/*')),\n",
        "len(glob.glob('/content/Dataset/labels/val/*')),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttlzMlDnhS9t",
        "outputId": "8d6ea197-4137-43a0-8a06-742c935f9e33"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4168 1050 4168 1050\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "아주 완벽하게 완성된 모습입니다^^\n",
        "\n",
        "참고로, 안좋은 예시처럼 클래스 별로 파일이름을 구분하게 되면 위의 코드블록에서 0 26 0 26이라는 값을 뱉어줍니다."
      ],
      "metadata": {
        "id": "OL7KlKc_0iJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "########################\n",
        "# 이 셀부터 코드 작성하세요\n",
        "########################\n",
        "# 3. 데이터를 Training set | Validation set으로 분할하세요.\n"
      ],
      "metadata": {
        "id": "1qfGCSqy_kL0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (2) json에서 정보 추출\n",
        "---\n",
        "- **세부요구사항**\n",
        "    - json 파일에서 필요한 정보를 추출하세요:\n",
        "        - 위치 정보 : x1, x2, y1, y2\n",
        "        - 박스 정보 : shape_type\n",
        "        - 클래스 정보 : labels\n",
        "    - 화폐당 하나의 클래스로 변경하세요.\n",
        "        - json 파일에는 화폐 클래스가 앞뒷면으로 구분되어 있습니다.\n",
        "        - 화폐의 앞뒷면 구분을 없애주세요.\n",
        "            - 예시 : 'ten_front', 'ten_back' -> 'ten'\n",
        "    - 화폐의 위치 정보를 YOLO 모델 형식에 맞게 변경 해주세요.\n",
        "        - 사용되는 이미지는 원본에서 1/5로 축소되어 있습니다.\n",
        "        - json 파일의 정보는 원본 기준 데이터이므로 위치 정보 추출을 할 때 x값과 y값을 1/5로 줄여주세요.\n",
        "    - 이렇게 변경된 정보를 YOLO label 형식에 맞게 txt파일로 저장 해 주세요.\n",
        "        - Hint : YOLO Labeling Format [label, x-center, y-center, width-norm, height-norm]\n",
        "---"
      ],
      "metadata": {
        "id": "II_hsJ6bKYGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json"
      ],
      "metadata": {
        "id": "MgUoCewjM-Jf"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_path = '/content/Dataset/labels/'\n",
        "temp_list = ['train', 'val']"
      ],
      "metadata": {
        "id": "gBD1Zv9BKaxi"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pisS3uf-0z3k",
        "outputId": "06508e20-0a0b-4c04-8dc1-a0f28aedd56d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mDataset\u001b[0m/  \u001b[01;34mDatasets_money\u001b[0m/  \u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "json파일을 하나만 열어봅시다"
      ],
      "metadata": {
        "id": "ZSgStBh31LS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/Dataset/labels/train/10000_B_DESK_0_1.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "data"
      ],
      "metadata": {
        "id": "Mzh2Y8doMEK1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86c4e63b-0326-4515-fe3c-8d20adc403ed"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'version': '3.16.7',\n",
              " 'flags': {},\n",
              " 'shapes': [{'label': 'Ten_Thousand_back',\n",
              "   'line_color': None,\n",
              "   'fill_color': None,\n",
              "   'points': [[389.19400127999995, 1505.904624],\n",
              "    [2539.7390591999997, 2508.0394751999997]],\n",
              "   'shape_type': 'rectangle',\n",
              "   'flags': {}}],\n",
              " 'lineColor': [0, 255, 0, 128],\n",
              " 'fillColor': [255, 0, 0, 128],\n",
              " 'imagePath': '10000_B_DESK_0_1.jpg',\n",
              " 'imageWidth': 3024,\n",
              " 'imageHeight': 4032,\n",
              " 'imageData': None}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dict 타입(딕셔너리)으로 정보를 담고있는 모습을 볼 수 있습니다.\n",
        "\n",
        "먼저 우리가 필요한 데이터가 무엇인지 파악해봅시다"
      ],
      "metadata": {
        "id": "O3KLdCwt1Xeh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###필요한 정보\n",
        "- 'shapes' : list > 각 box에 대한 정보를 담음\n",
        "    - 'label' : str > class 정보\n",
        "    - 'points' : 2중 list > box 좌표\n",
        "- 'imageWidth' : int > 원래 이미지 너비\n",
        "- 'imageHeight' : int > 원래 이미지 높이"
      ],
      "metadata": {
        "id": "2X_dg6X01uyw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "key값을 통해 dict 내부 요소들에 접근해서 우리가 원하는 데이터들을 뽑아와 봅시다"
      ],
      "metadata": {
        "id": "TZK-ASVr16Sf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_in_need = data['shapes'][0]['label'], data['shapes'][0]['points'], data['imageWidth'], data['imageHeight']\n",
        "data_in_need"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCotgP9Y1Qw_",
        "outputId": "878f7f08-f142-40bc-a80d-310c9cfde348"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Ten_Thousand_back',\n",
              " [[389.19400127999995, 1505.904624], [2539.7390591999997, 2508.0394751999997]],\n",
              " 3024,\n",
              " 4032)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### json 파일에서 우리가 원하는 정보를 추출하기\n",
        "하나의 json 파일을 까서 정보를 빼오는 코드를 바탕삼아서 전체 json 파일을 확인해서 정보를 빼오는 코드를 만들어봅시다."
      ],
      "metadata": {
        "id": "vSxspSKd2Uh7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "다른 모델을 가져다 쓸 경우 **데이터의 형식이나, 폴더의 구조, 심지어는 폴더의 이름마저 신경써서 설정**해야 합니다.\n",
        "\n",
        "이번 같은 경우에는 label 폴더 속 train 폴더와 val 폴더에 json 파일이 있으면 안되므로, json 파일들을 담고 있는 train 폴더와 val 폴더의 이름을 각각 train_json, val_json으로 바꿔주겠습니다.\n",
        "\n",
        "그 후, 새롭게 train 폴더와 val 폴더를 만듭시다!"
      ],
      "metadata": {
        "id": "YaVSMVVM2zes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.rename('/content/Dataset/labels/train', '/content/Dataset/labels/train_json')\n",
        "os.rename('/content/Dataset/labels/val', '/content/Dataset/labels/val_json')"
      ],
      "metadata": {
        "id": "73qwDrg_UnZh"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir('/content/Dataset/labels/train')\n",
        "os.mkdir('/content/Dataset/labels/val')"
      ],
      "metadata": {
        "id": "r1xxwjKeU6he"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 항상 확인하는 습관을 들입시다~~~~~!\n",
        "train_labels_path = glob.glob('/content/Dataset/labels/train_json/*')\n",
        "val_labels_path = glob.glob('/content/Dataset/labels/val_json/*')\n",
        "\n",
        "len(train_labels_path), len(val_labels_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Odz-tOruDvv3",
        "outputId": "01cf4a1d-759a-441e-bc4b-69fcde225791"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4168, 1050)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels_path[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6Gj04TOI2Bw",
        "outputId": "aa522dcc-0edc-4a33-bbef-d6ebb3bd612f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/Dataset/labels/train_json/10000_F_DESK_0_120.json',\n",
              " '/content/Dataset/labels/train_json/10000_F_STUFF_0_52.json',\n",
              " '/content/Dataset/labels/train_json/500_1197_9.json',\n",
              " '/content/Dataset/labels/train_json/10000_B_DESK_0_101.json',\n",
              " '/content/Dataset/labels/train_json/1000_B_HAND_0_61.json']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 정보 추출해서 txt파일에 담아 저장하기\n",
        "\n",
        "1. label 데이터가 담긴 파일의 경로들을 담은 리스트에서 각 파일 경로를 가져온다.\n",
        "2. with 구문을 이용해 파일을 열고 json 데이터를 가져온다.\n",
        "3. key 값을 사용해 필요한 정보에 접근하고, 적절한 처리과정을 거친 후, 변수에 저장한다.\n",
        "4. 다시 with 구문을 이용해 이번엔 새 txt파일을 생성하고 변수들을 str 데이터 타입으로 바꾼뒤에 집어넣고 저장한다.\n",
        "5. 1~4를 모든 json 파일에 적용한다."
      ],
      "metadata": {
        "id": "-F6Lai4z3-sx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# won_list = ['10', '50', '100', '500', '1000', '5000', '10000', '50000']\n",
        "# train json 파일들\n",
        "\n",
        "for filepath in train_labels_path:\n",
        "\n",
        "    with open(f'{filepath}') as f:\n",
        "        data = json.load(f)\n",
        "    \n",
        "    # class 파악\n",
        "    class_info = data['shapes'][0]['label'].split('_')\n",
        "    first = class_info[0]\n",
        "    second = class_info[1]\n",
        "    \n",
        "    if first == 'Ten':\n",
        "        if second == 'Thousand':\n",
        "            # 10,000 : 6\n",
        "            cls = 6\n",
        "        else:\n",
        "            # 10 : 0\n",
        "            cls = 0\n",
        "    elif first =='Fifty':\n",
        "        if second == 'Thousand':\n",
        "            # 50,000 : 7\n",
        "            cls = 7\n",
        "        else:\n",
        "            # 50 : 1\n",
        "            cls = 1\n",
        "    elif first == 'Hundred':\n",
        "        # 100 : 2\n",
        "        cls = 2\n",
        "    elif first == 'Five':\n",
        "        if second == ' Hundred':\n",
        "            # 500 : 3\n",
        "            cls = 3\n",
        "        else:\n",
        "            # 5,000 : 5\n",
        "            cls = 5\n",
        "    else:\n",
        "        # 1,000 : 4\n",
        "        cls = 4\n",
        "    #print(cls)\n",
        "\n",
        "    # 전체 이미지 크기\n",
        "    width, height = data['imageWidth'], data['imageHeight']\n",
        "\n",
        "    # box 중심점\n",
        "    point_info = data['shapes'][0]['points']\n",
        "    x1, y1 = point_info[0]\n",
        "    x2, y2 = point_info[1]\n",
        "        \n",
        "        # 중심점 계산\n",
        "    x_mid = (x1 + x2) / 2\n",
        "    y_mid = (y1 + y2) / 2\n",
        "        # 정규화 계산\n",
        "    x_mid_sc = x_mid / width\n",
        "    y_mid_sc = y_mid / height\n",
        "    #print(x_mid_sc, y_mid_sc)\n",
        "\n",
        "    # box 높이, 너비\n",
        "    box_width = (x2 - x1) / width\n",
        "    box_height = (y2 - y1) / height\n",
        "    \n",
        "    # 파일 이름 추출하기\n",
        "        # file_route: list > 현재 파일에 대한 모든 상위 폴더의 이름을 담은 리스트\n",
        "    file_route = filepath.split('/')\n",
        "        # 확장자 제거해주기\n",
        "    filename, ext = file_route[-1].split('.')\n",
        "        # 숙제 : 파일 이름을 '_'로 split 해서 class 정보를 알아낼 수 있습니다(서연님의 아이디어).\n",
        "        # 내일까지 숙제입니다^^. \n",
        "\n",
        "    # txt 파일 새로 작성해서 저장하기\n",
        "    with open(f'/content/Dataset/labels/train/{filename}.txt', 'w') as txt_f:\n",
        "        information = [cls, x_mid_sc, y_mid_sc, box_width, box_height]\n",
        "        txt_f.write(' '.join(map(str, information)))"
      ],
      "metadata": {
        "id": "ptqry1rxImgP"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# val json 파일들\n",
        "\n",
        "for filepath in val_labels_path:\n",
        "\n",
        "    with open(f'{filepath}') as f:\n",
        "        data = json.load(f)\n",
        "    \n",
        "    # class 파악\n",
        "    class_info = data['shapes'][0]['label'].split('_')\n",
        "    first = class_info[0]\n",
        "    second = class_info[1]\n",
        "    \n",
        "    if first == 'Ten':\n",
        "        if second == 'Thousand':\n",
        "            # 10,000 : 6\n",
        "            cls = 6\n",
        "        else:\n",
        "            # 10 : 0\n",
        "            cls = 0\n",
        "    elif first =='Fifty':\n",
        "        if second == 'Thousand':\n",
        "            # 50,000 : 7\n",
        "            cls = 7\n",
        "        else:\n",
        "            # 50 : 1\n",
        "            cls = 1\n",
        "    elif first == 'Hundred':\n",
        "        # 100 : 2\n",
        "        cls = 2\n",
        "    elif first == 'Five':\n",
        "        if second == ' Hundred':\n",
        "            # 500 : 3\n",
        "            cls = 3\n",
        "        else:\n",
        "            # 5,000 : 5\n",
        "            cls = 5\n",
        "    else:\n",
        "        # 1,000 : 4\n",
        "        cls = 4\n",
        "    #print(cls)\n",
        "\n",
        "    # 전체 이미지 크기\n",
        "    width, height = data['imageWidth'], data['imageHeight']\n",
        "\n",
        "    # box 중심점\n",
        "    point_info = data['shapes'][0]['points']\n",
        "    x1, y1 = point_info[0]\n",
        "    x2, y2 = point_info[1]\n",
        "        \n",
        "        # 중심점 계산\n",
        "    x_mid = (x1 + x2) / 2\n",
        "    y_mid = (y1 + y2) / 2\n",
        "        # 정규화 계산\n",
        "    x_mid_sc = x_mid / width\n",
        "    y_mid_sc = y_mid / height\n",
        "    #print(x_mid_sc, y_mid_sc)\n",
        "\n",
        "    # box 높이, 너비\n",
        "    box_width = (x2 - x1) / width\n",
        "    box_height = (y2 - y1) / height\n",
        "    \n",
        "    # 파일 이름 추출하기\n",
        "        # file_route: list > 현재 파일에 대한 모든 상위 폴더의 이름을 담은 리스트\n",
        "    file_route = filepath.split('/')\n",
        "        # 확장자 제거해주기\n",
        "    filename, ext = file_route[-1].split('.')\n",
        "\n",
        "    with open(f'/content/Dataset/labels/val/{filename}.txt', 'w') as txt_f:\n",
        "        information = [cls, x_mid_sc, y_mid_sc, box_width, box_height]\n",
        "        txt_f.write(' '.join(map(str, information)))"
      ],
      "metadata": {
        "id": "nBbjI1jwV0Q8"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 확인은 필수입니다다\n",
        "len(glob.glob('/content/Dataset/labels/train/*')), len(glob.glob('/content/Dataset/labels/val/*'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3R5up2BRlHm",
        "outputId": "0d7b268d-4b0b-4200-98e2-5744f4ed0942"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4168, 1050)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOQeEhApesWR"
      },
      "source": [
        "### (3) 데이터셋 정보가 담긴 파일 생성\n",
        "---\n",
        "- **세부요구사항**\n",
        "    - 파일 안에 있어야 할 정보는 아래와 같습니다.\n",
        "        - 학습할 클래스 이름 정보\n",
        "        - 학습할 클래스 수 정보\n",
        "        - Training, Validation 데이터셋 위치 정보\n",
        "---\n",
        "- 가장 대중적으로 이용하는 라이브러리는 yaml 입니다.\n",
        "    - [yaml document](https://pyyaml.org/wiki/PyYAMLDocumentation)\n",
        "    - 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "pu1iQfQolBhJ"
      },
      "outputs": [],
      "source": [
        "import yaml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "won_dict = {0:'10', 1:'50', 2:'100', 3:'500', 4:'1000', 5:'5000', 6:'10000', 7:'50000'}"
      ],
      "metadata": {
        "id": "t1_uOeXcSvv3"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "qvMQcHirmSnD"
      },
      "outputs": [],
      "source": [
        "########################\n",
        "# 이 셀부터 코드 작성하세요\n",
        "########################\n",
        "# 언젠가 우리는 일일이 손으로 쓰지 못할 만큼 어마무시한 클래스의 숫자를 가진진 다중 분류 문제를 만날 수 있습니다.\n",
        "# 그러니 f-string을 통해 코딩하는 습관을 기르도록 합시다.\n",
        "\n",
        "document = f'''\n",
        "path: /content/Dataset\n",
        "train: images/train\n",
        "val: images/val\n",
        "\n",
        "\n",
        "nc: {len(won_list)}\n",
        "names: {won_list}\n",
        "\n",
        "'''\n",
        "with open('/content/Dataset/money.yaml', 'w') as f:\n",
        "    f.write(document)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.모델링"
      ],
      "metadata": {
        "id": "3btFvySXi2dt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pQ2gRbTYgLL"
      },
      "source": [
        "### (1) 모델 라이브러리 설치\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jedi"
      ],
      "metadata": {
        "id": "73a1l-ZQuHyF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21291c5d-046f-4b79-8674-94928bdc2aa5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jedi\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi) (0.8.3)\n",
            "Installing collected packages: jedi\n",
            "Successfully installed jedi-0.18.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5"
      ],
      "metadata": {
        "id": "Biyr9AHkMyNf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96394c4d-9738-42fc-8813-47588c08aecc"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 15338, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 15338 (delta 0), reused 2 (delta 0), pack-reused 15335\u001b[K\n",
            "Receiving objects: 100% (15338/15338), 14.21 MiB | 19.10 MiB/s, done.\n",
            "Resolving deltas: 100% (10520/10520), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## yolov5 폴더 requirements.txt 수정 필요\n",
        "## setuptools<=64.0.2\n",
        "\n",
        "temp_str = 'setuptools<=64.0.2\\n'\n",
        "\n",
        "f = open('/content/yolov5/requirements.txt', 'r')\n",
        "f_str = f.readlines()\n",
        "f.close()\n",
        "\n",
        "f2 = open('/content/yolov5/requirements.txt', 'w')\n",
        "\n",
        "for idx, val in enumerate(f_str):\n",
        "    if 'setuptools' in val:\n",
        "        idx_v = idx\n",
        "        f_str.remove(val)\n",
        "        f_str.insert(idx_v, temp_str)\n",
        "\n",
        "for val in f_str:\n",
        "    f2.write(val)\n",
        "\n",
        "f2.close()"
      ],
      "metadata": {
        "id": "W3JjyVOpg26s"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "6xD6tBTdMyNg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bae4b12-0dc2-4f25-a85b-b80af4cb0ae7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gitpython>=3.1.30\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 7)) (1.22.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 8)) (4.7.0.72)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 9)) (8.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 10)) (5.9.4)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 11)) (6.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 12)) (2.27.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 13)) (1.10.1)\n",
            "Collecting thop>=0.1.1\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 15)) (1.13.1+cu116)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 16)) (0.14.1+cu116)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 17)) (4.65.0)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 21)) (2.11.2)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 26)) (1.4.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 27)) (0.12.2)\n",
            "Collecting setuptools<=64.0.2\n",
            "  Downloading setuptools-64.0.2-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (4.39.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (5.12.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (1.4.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (1.0.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (23.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (3.0.9)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2022.12.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (4.5.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.40.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.8.1)\n",
            "Requirement already satisfied: protobuf<4,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (3.19.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (2.16.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (2.2.3)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.51.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 26)) (2022.7.1)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (5.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.16.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.3.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=3.2.2->-r requirements.txt (line 6)) (3.15.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 21)) (6.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 21)) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 21)) (3.2.2)\n",
            "Installing collected packages: smmap, setuptools, thop, gitdb, gitpython\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.6.0\n",
            "    Uninstalling setuptools-67.6.0:\n",
            "      Successfully uninstalled setuptools-67.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cvxpy 1.3.1 requires setuptools>65.5.1, but you have setuptools 64.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gitdb-4.0.10 gitpython-3.1.31 setuptools-64.0.2 smmap-5.0.0 thop-0.1.1.post2209072238\n"
          ]
        }
      ],
      "source": [
        "!cd yolov5; pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd yolov5; pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtNsZ0SXpjjK",
        "outputId": "5b004d95-88c7-4169-bc2e-4efedfae0b53"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 5)) (3.1.31)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 7)) (1.22.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 8)) (4.7.0.72)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 9)) (8.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 10)) (5.9.4)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 11)) (6.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 12)) (2.27.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 13)) (1.10.1)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 14)) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 15)) (1.13.1+cu116)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 16)) (0.14.1+cu116)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 17)) (4.65.0)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 21)) (2.11.2)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 26)) (1.4.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 27)) (0.12.2)\n",
            "Requirement already satisfied: setuptools<=64.0.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 41)) (64.0.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.10)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (1.0.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (4.39.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (0.11.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (5.12.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.0.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (4.5.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (2.2.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (2.16.2)\n",
            "Requirement already satisfied: protobuf<4,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (3.19.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.6.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.40.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.8.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.51.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.4.6)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 26)) (2022.7.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.2.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.16.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.3.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=3.2.2->-r requirements.txt (line 6)) (3.15.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 21)) (6.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 21)) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 21)) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "만약 에러가 나면 그냥 한번 더 돌려주시면 됩니다."
      ],
      "metadata": {
        "id": "WxHIFoLP8qGW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (2) 가중치 파일 다운로드\n",
        "---\n",
        "- **세부요구사항**\n",
        "    - 모델 개발자가 제공하는 사전 학습 가중치 파일을 다운로드 하세요.\n",
        "        - 해당 과정이 불필요하다면 넘어가셔도 됩니다!\n",
        "---"
      ],
      "metadata": {
        "id": "_mHMAspjR6Xp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pre-trained 모델을 저장할 폴더를 만들어 둡시다"
      ],
      "metadata": {
        "id": "qm2_2MLH8ysp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "########################\n",
        "# 이 셀부터 코드 작성하세요\n",
        "########################\n",
        "os.mkdir('/content/yolov5/pretrained')"
      ],
      "metadata": {
        "id": "sSVIqkMLDIOd"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "yolov5를 만든 사람들의 github 주소로 가서 pre_trained된 yolov5 모델에 대한 다운로드 링크를 가져와서 파이썬 코드로 다운로드 해봅시다."
      ],
      "metadata": {
        "id": "M26TfEIu9t2E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**직접 한번 해보세요!**"
      ],
      "metadata": {
        "id": "_pxBA-qR9wbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O '/content/yolov5/pretrained/yolov5m.pt' 'https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5m.pt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJE_jPJLbZrQ",
        "outputId": "8e71cb38-0764-4e8a-de65-e2ad5871852f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-24 06:25:19--  https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5m.pt\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/7acc87ed-9e1f-4d4a-8bdc-0912393948df?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230324%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230324T062520Z&X-Amz-Expires=300&X-Amz-Signature=c9a7482be039a7d12c3e137244a6bc268432646536ce1f4ff24f4ad0f0bf899a&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5m.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-03-24 06:25:20--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/7acc87ed-9e1f-4d4a-8bdc-0912393948df?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230324%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230324T062520Z&X-Amz-Expires=300&X-Amz-Signature=c9a7482be039a7d12c3e137244a6bc268432646536ce1f4ff24f4ad0f0bf899a&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5m.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42806829 (41M) [application/octet-stream]\n",
            "Saving to: ‘/content/yolov5/pretrained/yolov5m.pt’\n",
            "\n",
            "/content/yolov5/pre 100%[===================>]  40.82M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-03-24 06:25:20 (411 MB/s) - ‘/content/yolov5/pretrained/yolov5m.pt’ saved [42806829/42806829]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8-5lC4mfbwT"
      },
      "source": [
        "### (3) 학습 : train.py\n",
        "---\n",
        "- **세부요구사항**\n",
        "    - UltraLytics YOLO v5에는 아래의 데이터가 필요합니다.\n",
        "        - 데이터셋 정보가 담긴 yaml 파일\n",
        "        - 사용하려는 모델 구조에 대한 yaml 파일\n",
        "        - 사용하려는 모델의 가중치 파일\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "epoch 한번이 정상적으로 돌아가는지만 확인합시다다"
      ],
      "metadata": {
        "id": "-yLv_osw-LEl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "4AYFDMaVfmTK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c31b43a2-6637-4be6-9c68-31e6a261cda8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=/content/yolov5/pretrained/yolov5m.pt, cfg=/content/yolov5/models/yolov5m.yaml, data=/content/Dataset/money.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=1000, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=/content/drive/MyDrive/ktaivle_mp3th_2, name=train_money1, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=9, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-128-gb96f35c Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/ktaivle_mp3th_2', view at http://localhost:6006/\n",
            "2023-03-24 00:45:54.355551: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-24 00:45:54.512162: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-03-24 00:45:55.332514: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-03-24 00:45:55.332634: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-03-24 00:45:55.332654: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 123MB/s]\n",
            "Overriding model.yaml nc=80 with nc=8\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
            "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
            "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
            "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
            "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
            "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
            "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
            "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
            "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
            "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
            " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
            " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
            " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
            " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
            " 24      [17, 20, 23]  1     52533  models.yolo.Detect                      [8, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
            "YOLOv5m summary: 291 layers, 20899605 parameters, 20899605 gradients, 48.3 GFLOPs\n",
            "\n",
            "Transferred 474/481 items from /content/yolov5/pretrained/yolov5m.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Dataset/labels/train... 4168 images, 0 backgrounds, 0 corrupt: 100% 4168/4168 [00:00<00:00, 8357.92it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Dataset/labels/train.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Dataset/labels/val... 1050 images, 0 backgrounds, 0 corrupt: 100% 1050/1050 [00:00<00:00, 5307.54it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Dataset/labels/val.cache\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.01 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to /content/drive/MyDrive/ktaivle_mp3th_2/train_money1/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/ktaivle_mp3th_2/train_money1\u001b[0m\n",
            "Starting training for 1000 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      0/999       6.2G    0.05112     0.0208    0.05185         20        640: 100% 261/261 [00:43<00:00,  5.99it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.52it/s]\n",
            "                   all       1050       1050      0.188      0.705      0.356      0.179\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      1/999      7.77G    0.03681    0.01063    0.03455         16        640: 100% 261/261 [00:37<00:00,  6.99it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.41it/s]\n",
            "                   all       1050       1050      0.581      0.796       0.73      0.492\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      2/999      7.77G    0.03481   0.008374    0.02126         20        640: 100% 261/261 [00:36<00:00,  7.09it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.16it/s]\n",
            "                   all       1050       1050      0.745      0.855      0.885      0.692\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      3/999      7.77G    0.02924   0.007584    0.01869         20        640: 100% 261/261 [00:36<00:00,  7.14it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  5.53it/s]\n",
            "                   all       1050       1050       0.64      0.677       0.72      0.586\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      4/999      7.77G    0.02503    0.00688    0.01602         15        640: 100% 261/261 [00:36<00:00,  7.21it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  5.58it/s]\n",
            "                   all       1050       1050      0.871      0.825      0.941      0.773\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      5/999      7.77G    0.02271   0.006484    0.01351         16        640: 100% 261/261 [00:36<00:00,  7.24it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.41it/s]\n",
            "                   all       1050       1050      0.941      0.949      0.976      0.853\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      6/999      7.77G    0.02135   0.006123    0.01242         21        640: 100% 261/261 [00:36<00:00,  7.10it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.38it/s]\n",
            "                   all       1050       1050      0.954      0.948      0.979      0.863\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      7/999      7.77G    0.02026   0.006159    0.01283         17        640: 100% 261/261 [00:36<00:00,  7.11it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  5.56it/s]\n",
            "                   all       1050       1050      0.966      0.949      0.986      0.872\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      8/999      7.77G    0.01903   0.005926    0.01176         19        640: 100% 261/261 [00:36<00:00,  7.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.46it/s]\n",
            "                   all       1050       1050      0.958      0.981      0.987      0.898\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      9/999      7.77G     0.0184   0.005801    0.01183         19        640: 100% 261/261 [00:37<00:00,  7.05it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.34it/s]\n",
            "                   all       1050       1050      0.948      0.911      0.977      0.877\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     10/999      7.77G    0.01803   0.005623    0.01018         24        640: 100% 261/261 [00:37<00:00,  6.96it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.19it/s]\n",
            "                   all       1050       1050      0.954      0.937      0.977      0.857\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     11/999      7.77G    0.01751   0.005623     0.0103         23        640: 100% 261/261 [00:36<00:00,  7.09it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  5.53it/s]\n",
            "                   all       1050       1050      0.981       0.97      0.991      0.906\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     12/999      7.77G    0.01672   0.005457   0.009513         17        640: 100% 261/261 [00:37<00:00,  6.96it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.38it/s]\n",
            "                   all       1050       1050      0.974       0.99      0.993      0.917\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     13/999      7.77G    0.01645   0.005316   0.009722         19        640: 100% 261/261 [00:37<00:00,  6.95it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.36it/s]\n",
            "                   all       1050       1050      0.979      0.976       0.99      0.921\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     14/999      7.77G    0.01605   0.005362   0.009536         23        640: 100% 261/261 [00:37<00:00,  6.92it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.24it/s]\n",
            "                   all       1050       1050      0.972      0.956      0.988      0.901\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     15/999      7.77G    0.01607   0.005222   0.009032         22        640: 100% 261/261 [00:36<00:00,  7.09it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.47it/s]\n",
            "                   all       1050       1050      0.969      0.975      0.988      0.927\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     16/999      7.77G    0.01484   0.005082   0.008921         20        640: 100% 261/261 [00:37<00:00,  6.97it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.31it/s]\n",
            "                   all       1050       1050      0.977      0.979       0.99      0.942\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     17/999      7.77G    0.01473   0.005061   0.008841         10        640: 100% 261/261 [00:37<00:00,  7.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.36it/s]\n",
            "                   all       1050       1050      0.985      0.972      0.992      0.932\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     18/999      7.77G    0.01458   0.004979    0.00848         19        640: 100% 261/261 [00:37<00:00,  6.92it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.42it/s]\n",
            "                   all       1050       1050      0.969      0.965      0.991       0.92\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     19/999      7.77G    0.01455   0.004917   0.007483         23        640: 100% 261/261 [00:37<00:00,  6.95it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  5.51it/s]\n",
            "                   all       1050       1050      0.991      0.988      0.995      0.954\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     20/999      7.77G    0.01407   0.004837   0.007574         13        640: 100% 261/261 [00:37<00:00,  6.94it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.28it/s]\n",
            "                   all       1050       1050      0.983       0.99      0.994      0.947\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     21/999      7.77G    0.01362   0.004784   0.008368         21        640: 100% 261/261 [00:37<00:00,  6.95it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.31it/s]\n",
            "                   all       1050       1050      0.991      0.982      0.993      0.941\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     22/999      7.77G    0.01354   0.004632   0.006577         13        640: 100% 261/261 [00:37<00:00,  6.99it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.40it/s]\n",
            "                   all       1050       1050      0.978      0.981      0.992      0.948\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     23/999      7.77G    0.01382   0.004821    0.00782         12        640: 100% 261/261 [00:37<00:00,  7.00it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  5.52it/s]\n",
            "                   all       1050       1050      0.991      0.993      0.994      0.952\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     24/999      7.77G    0.01314   0.004666   0.007033         16        640: 100% 261/261 [00:37<00:00,  7.01it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.35it/s]\n",
            "                   all       1050       1050      0.985      0.986      0.991      0.958\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     25/999      7.77G    0.01321   0.004637   0.006651         15        640: 100% 261/261 [00:37<00:00,  7.00it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.36it/s]\n",
            "                   all       1050       1050      0.997      0.997      0.995       0.95\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     26/999      7.77G     0.0127   0.004516   0.007024         17        640: 100% 261/261 [00:37<00:00,  6.94it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.31it/s]\n",
            "                   all       1050       1050      0.986      0.972      0.991      0.948\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     27/999      7.77G    0.01259    0.00456   0.006932         18        640: 100% 261/261 [00:37<00:00,  6.91it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.35it/s]\n",
            "                   all       1050       1050      0.984       0.99      0.994      0.962\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     28/999      7.77G    0.01276   0.004444    0.00651         12        640: 100% 261/261 [00:37<00:00,  7.04it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.32it/s]\n",
            "                   all       1050       1050      0.994      0.992      0.995      0.977\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     29/999      7.77G    0.01248   0.004488   0.006663         20        640: 100% 261/261 [00:37<00:00,  7.01it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.23it/s]\n",
            "                   all       1050       1050      0.991      0.983      0.994       0.97\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     30/999      7.77G    0.01233   0.004338   0.006643         21        640: 100% 261/261 [00:37<00:00,  7.05it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.32it/s]\n",
            "                   all       1050       1050       0.99      0.981      0.994      0.968\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     31/999      7.77G    0.01214   0.004357   0.006225         10        640: 100% 261/261 [00:37<00:00,  6.93it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.37it/s]\n",
            "                   all       1050       1050      0.992      0.991      0.994      0.967\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     32/999      7.77G    0.01218   0.004351   0.006026         14        640: 100% 261/261 [00:37<00:00,  7.00it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.31it/s]\n",
            "                   all       1050       1050      0.991      0.996      0.995      0.971\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     33/999      7.77G    0.01196   0.004339   0.005747         15        640: 100% 261/261 [00:37<00:00,  7.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.32it/s]\n",
            "                   all       1050       1050      0.997      0.987      0.995      0.974\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     34/999      7.77G    0.01182   0.004166   0.005509         21        640: 100% 261/261 [00:37<00:00,  7.05it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.35it/s]\n",
            "                   all       1050       1050      0.994      0.994      0.995      0.978\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     35/999      7.77G    0.01155   0.004189   0.005768         18        640: 100% 261/261 [00:37<00:00,  7.01it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.38it/s]\n",
            "                   all       1050       1050      0.992      0.996      0.995      0.973\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     36/999      7.77G    0.01147   0.004189   0.005417         14        640: 100% 261/261 [00:37<00:00,  6.99it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.32it/s]\n",
            "                   all       1050       1050      0.986      0.993      0.993      0.972\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     37/999      7.77G    0.01138   0.004171   0.006067         18        640: 100% 261/261 [00:37<00:00,  7.00it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.44it/s]\n",
            "                   all       1050       1050      0.994      0.994      0.994      0.972\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     38/999      7.77G    0.01125   0.004189   0.005521         22        640: 100% 261/261 [00:36<00:00,  7.24it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.46it/s]\n",
            "                   all       1050       1050      0.999      0.997      0.995      0.979\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     39/999      7.77G    0.01149    0.00407   0.005348         20        640: 100% 261/261 [00:37<00:00,  7.05it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  5.58it/s]\n",
            "                   all       1050       1050      0.996       0.99      0.995      0.967\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     40/999      7.77G    0.01136   0.004179   0.005712         16        640: 100% 261/261 [00:36<00:00,  7.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.48it/s]\n",
            "                   all       1050       1050      0.995      0.992      0.995      0.972\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     41/999      7.77G    0.01094   0.004032   0.005253         18        640: 100% 261/261 [00:36<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.49it/s]\n",
            "                   all       1050       1050       0.99      0.992      0.993      0.967\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     42/999      7.77G    0.01128   0.004121   0.005872         19        640: 100% 261/261 [00:36<00:00,  7.12it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.50it/s]\n",
            "                   all       1050       1050      0.999      0.994      0.995      0.976\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     43/999      7.77G     0.0114   0.004153   0.005247         19        640: 100% 261/261 [00:36<00:00,  7.10it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.45it/s]\n",
            "                   all       1050       1050      0.996      0.999      0.995      0.981\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     44/999      7.77G    0.01083   0.003933   0.004435         13        640: 100% 261/261 [00:36<00:00,  7.15it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.49it/s]\n",
            "                   all       1050       1050      0.995      0.987      0.994      0.978\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     45/999      7.77G    0.01112   0.004007   0.005042         14        640: 100% 261/261 [00:36<00:00,  7.11it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  5.62it/s]\n",
            "                   all       1050       1050      0.994      0.994      0.995      0.976\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     46/999      7.77G    0.01095   0.004058   0.004873         13        640: 100% 261/261 [00:36<00:00,  7.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  5.57it/s]\n",
            "                   all       1050       1050      0.991      0.994      0.994      0.979\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     47/999      7.77G    0.01087   0.004043   0.004817         18        640: 100% 261/261 [00:36<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  5.58it/s]\n",
            "                   all       1050       1050      0.992      0.995      0.995      0.978\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     48/999      7.77G     0.0107   0.003953   0.005394         14        640: 100% 261/261 [00:36<00:00,  7.13it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  5.53it/s]\n",
            "                   all       1050       1050      0.997          1      0.995      0.979\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     49/999      7.77G    0.01067   0.004024   0.005136         21        640: 100% 261/261 [00:36<00:00,  7.14it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  5.51it/s]\n",
            "                   all       1050       1050      0.997      0.995      0.995      0.984\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     50/999      7.77G    0.01067   0.003911   0.004424         14        640: 100% 261/261 [00:36<00:00,  7.12it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.49it/s]\n",
            "                   all       1050       1050      0.996      0.997      0.995       0.98\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     51/999      7.77G    0.01048   0.003822   0.005225         17        640: 100% 261/261 [00:36<00:00,  7.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  5.58it/s]\n",
            "                   all       1050       1050      0.997      0.995      0.995      0.982\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     52/999      7.77G     0.0106   0.003967    0.00459         22        640: 100% 261/261 [00:36<00:00,  7.15it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  5.57it/s]\n",
            "                   all       1050       1050      0.998      0.999      0.995      0.982\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     53/999      7.77G    0.01039   0.003825   0.004207         24        640: 100% 261/261 [00:36<00:00,  7.12it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  5.55it/s]\n",
            "                   all       1050       1050      0.997      0.997      0.995      0.985\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     54/999      7.77G    0.01011   0.003813   0.004507         11        640: 100% 261/261 [00:36<00:00,  7.21it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.48it/s]\n",
            "                   all       1050       1050      0.999      0.998      0.995      0.985\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     55/999      7.77G    0.01046   0.003963   0.004359         17        640: 100% 261/261 [00:36<00:00,  7.10it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.47it/s]\n",
            "                   all       1050       1050      0.997      0.997      0.995      0.983\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     56/999      7.77G    0.01004   0.003792   0.004368         19        640: 100% 261/261 [00:36<00:00,  7.12it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.50it/s]\n",
            "                   all       1050       1050      0.994          1      0.995      0.985\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     57/999      7.77G    0.01028   0.003759   0.004509         17        640: 100% 261/261 [00:36<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  5.55it/s]\n",
            "                   all       1050       1050      0.992      0.998      0.995      0.985\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     58/999      7.77G    0.01013   0.003857   0.004624         18        640: 100% 261/261 [00:36<00:00,  7.11it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  5.56it/s]\n",
            "                   all       1050       1050      0.995      0.999      0.995      0.988\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     59/999      7.77G    0.01036   0.003801   0.003894         26        640: 100% 261/261 [00:36<00:00,  7.13it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.48it/s]\n",
            "                   all       1050       1050      0.998      0.997      0.995      0.982\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     60/999      7.77G    0.01003   0.003843   0.004384         20        640: 100% 261/261 [00:36<00:00,  7.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.48it/s]\n",
            "                   all       1050       1050      0.999      0.998      0.995      0.984\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     61/999      7.77G    0.01005   0.003795   0.004425         16        640: 100% 261/261 [00:36<00:00,  7.12it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  5.55it/s]\n",
            "                   all       1050       1050      0.998      0.991      0.995      0.983\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     62/999      7.77G   0.009851   0.003784   0.004186         17        640: 100% 261/261 [00:36<00:00,  7.23it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  5.51it/s]\n",
            "                   all       1050       1050      0.999      0.996      0.995      0.985\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     63/999      7.77G   0.009983   0.003746   0.004344         20        640: 100% 261/261 [00:36<00:00,  7.10it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  5.65it/s]\n",
            "                   all       1050       1050      0.999      0.997      0.995      0.986\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     64/999      7.77G   0.009989   0.003817   0.004069         22        640: 100% 261/261 [00:36<00:00,  7.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  5.60it/s]\n",
            "                   all       1050       1050      0.997      0.995      0.995      0.986\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     65/999      7.77G   0.009925   0.003713   0.004582         18        640: 100% 261/261 [00:36<00:00,  7.14it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  5.52it/s]\n",
            "                   all       1050       1050      0.999      0.995      0.995      0.985\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     66/999      7.77G       0.01   0.003733   0.004244         18        640: 100% 261/261 [00:36<00:00,  7.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.44it/s]\n",
            "                   all       1050       1050      0.997      0.998      0.995      0.988\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     67/999      7.77G   0.009764   0.003709   0.003875         17        640: 100% 261/261 [00:36<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  5.52it/s]\n",
            "                   all       1050       1050      0.997      0.998      0.995      0.986\n",
            "Stopping training early as no improvement observed in last 9 epochs. Best results observed at epoch 58, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=9) pass a new patience value, i.e. `python train.py --patience 300` or use `--patience 0` to disable EarlyStopping.\n",
            "\n",
            "68 epochs completed in 0.832 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/ktaivle_mp3th_2/train_money1/weights/last.pt, 42.2MB\n",
            "Optimizer stripped from /content/drive/MyDrive/ktaivle_mp3th_2/train_money1/weights/best.pt, 42.2MB\n",
            "\n",
            "Validating /content/drive/MyDrive/ktaivle_mp3th_2/train_money1/weights/best.pt...\n",
            "Fusing layers... \n",
            "YOLOv5m summary: 212 layers, 20881221 parameters, 0 gradients, 47.9 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:08<00:00,  4.02it/s]\n",
            "                   all       1050       1050      0.995      0.999      0.995      0.988\n",
            "                    10       1050         88      0.993          1      0.995      0.986\n",
            "                    50       1050         89          1      0.995      0.995      0.983\n",
            "                   100       1050         89      0.989          1      0.995      0.986\n",
            "                  1000       1050        172      0.991          1      0.995      0.991\n",
            "                  5000       1050        263      0.998          1      0.995      0.989\n",
            "                 10000       1050        174      0.998          1      0.995       0.99\n",
            "                 50000       1050        175      0.998          1      0.995      0.989\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/ktaivle_mp3th_2/train_money1\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "########################\n",
        "# 이 셀부터 코드 작성하세요\n",
        "########################\n",
        "!cd yolov5; python train.py\\\n",
        "    --data '/content/Dataset/money.yaml' \\\n",
        "    --cfg '/content/yolov5/models/yolov5m.yaml' \\\n",
        "    --weights '/content/yolov5/pretrained/yolov5m.pt' \\\n",
        "    --epochs 1000 \\\n",
        "    --patience 9 \\\n",
        "    --img 640 \\\n",
        "    --project '/content/drive/MyDrive/ktaivle_mp3th_2' \\\n",
        "    --name 'train_money1' \\\n",
        "    --exist-ok"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2YESAa5fc4M"
      },
      "source": [
        "## 4.탐지 : detect.py\n",
        "---\n",
        "- **세부요구사항**\n",
        "    - 학습 과정에서 생성된 가중치 파일을 이용하세요.\n",
        "    - IoU threshold를 0.25 이하로 설정하세요.\n",
        "    - confidence threshold를 0.75 이상으로 설정하세요.\n",
        "---\n",
        "- 여러분이 **직접 촬영한 화폐 사진과 동영상**을 탐지 과정에 이용하여 결과를 확인하세요.\n",
        "    - 조건\n",
        "        1. 화폐의 수를 늘려가며 촬영 해보세요.\n",
        "            - ex) 50원 하나, 50원 둘, 50원 셋, ...\n",
        "        2. 화폐의 종류를 늘려가며 촬영 해보세요.\n",
        "            - ex) 50원 하나와 100원 하나, 50원 하나와 100원 하나와 1000원 하나, ...\n",
        "        3. 사진은 최소 30장 이상, 동영상은 최소 하나 이상 촬영하여 사용 해보세요.\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 테스트 이미지들을 담을 폴더를 생성한다.\n",
        "2. 그 폴더에 이미지들을 압축 해제한다\n",
        "3. detect 시작!"
      ],
      "metadata": {
        "id": "_4X6y_pfUJTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir('/content/test_images/')"
      ],
      "metadata": {
        "id": "5njyVxVIXa3F"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir('/content/test_videos/')"
      ],
      "metadata": {
        "id": "MOOE89llZsr3"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_zip_paths = glob.glob('/content/drive/MyDrive/ktaivle_mp3th_2/test_zip/*.zip') \n",
        "# test_data = zipfile.ZipFile()\n",
        "len(test_zip_paths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7EwEt7VTwIt",
        "outputId": "5fd25b94-1990-4722-d54d-c63f1998f313"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for zip_path in test_zip_paths:\n",
        "    testfile = zipfile.ZipFile(zip_path)\n",
        "    testfile.extractall('/content/test_images')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "6JQOEwIjWy_T",
        "outputId": "1020c69f-5b13-4d05-e170-4bc9b8e08011"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-b25d2290bc7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mzip_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_zip_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtestfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtestfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/test_images'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.9/zipfile.py\u001b[0m in \u001b[0;36mextractall\u001b[0;34m(self, path, members, pwd)\u001b[0m\n\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mzipinfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1642\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_member\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/zipfile.py\u001b[0m in \u001b[0;36m_extract_member\u001b[0;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[1;32m   1695\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1696\u001b[0m              \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1697\u001b[0;31m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/shutil.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0mfdst_write\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfsrc_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/zipfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eof\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/zipfile.py\u001b[0m in \u001b[0;36m_read1\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    990\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconsumed_tail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    993\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/zipfile.py\u001b[0m in \u001b[0;36m_read2\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compress_left\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compress_left\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/zipfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    742\u001b[0m                         \"Close the writing handle before trying to read.\")\n\u001b[1;32m    743\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for vid_path in glob.glob('/content/test_images/*mp4'):\n",
        "    shutil.move(vid_path, '/content/test_videos/')"
      ],
      "metadata": {
        "id": "JJJp_4cBY-UC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(glob.glob('/content/test_images/*')), len(glob.glob('/content/test_videos/*'))"
      ],
      "metadata": {
        "id": "GKL632vCackm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########################\n",
        "# 이 셀부터 코드 작성하세요\n",
        "########################\n",
        "!cd yolov5; python detect.py \\\n",
        "    --weights '/content/drive/MyDrive/ktaivle_mp3th_2/train_money1/weights/best.pt' \\\n",
        "    --source '/content/test_images/' \\\n",
        "    --project '/content/detected/' \\\n",
        "    --name 'images' \\\n",
        "    --img 640 \\\n",
        "    --conf-thres 0.75 \\\n",
        "    --iou-thres 0.3 \\\n",
        "    --line-thickness 2 \\\n",
        "    --exist-ok \n",
        "    # --device CPU"
      ],
      "metadata": {
        "id": "9rK0ClfTcjEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "detected_img_pathes = glob.glob('/content/detected/images/*')\n",
        "for detected_img_path in detected_img_pathes:\n",
        "    display(Image(filename=detected_img_path, width=640))\n",
        "\n"
      ],
      "metadata": {
        "id": "rt7Lv33lbszS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detected_img_pathes = glob.glob('/content/detected/images/*')"
      ],
      "metadata": {
        "id": "7nDlBqOUbEWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detected_img_pathes"
      ],
      "metadata": {
        "id": "eKtwfRLkb2ST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for detected_img_path in detected_img_pathes:\n",
        "    display(Image(filename=detected_img_path, width=640))"
      ],
      "metadata": {
        "id": "JJoB0E74bSUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "M7JSHOZ7iG2d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. val.py를 이용해 모델 성능평가하기"
      ],
      "metadata": {
        "id": "KqNjdr1BiKAq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. test 파일들을 담을 폴더들을 생성한다.\n",
        "2. test 이미지, 클래스 정보 파일을 지정된 경로에 넣는다.\n",
        "3. val py 실행!"
      ],
      "metadata": {
        "id": "W8g7rbrMpraG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이미지, 레이블 파일을 yolov5가 인식가능한 폴더 구조에 넣어두기"
      ],
      "metadata": {
        "id": "ZTrXSvObSnPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    os.mkdir('/content/Dataset/images/test')\n",
        "    os.mkdir('/content/Dataset/labels/test')\n",
        "except:\n",
        "    pass\n",
        "    "
      ],
      "metadata": {
        "id": "bmwjJSMdM4-_"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pt_zip = zipfile.ZipFile('/content/drive/MyDrive/ktaivle_mp3th_2/performence_test/test_img_with_label.zip')"
      ],
      "metadata": {
        "id": "EOGqP0tnN8U5"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pt_zip.extractall('/content/Dataset')"
      ],
      "metadata": {
        "id": "zHGKLyQJOGHb"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pt_filepaths = glob.glob('/content/Dataset/test_img_with_label/*txt')\n",
        "# test_data = zipfile.ZipFile()\n",
        "len(pt_filepaths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOhP3VSMNgwl",
        "outputId": "545945f2-ca31-45de-c159-4c5f8cf0ebce"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "101"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pt_filepaths"
      ],
      "metadata": {
        "id": "vcFhgDI9RCXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pt_filepaths[0][-4:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PZMwxhz0P8g9",
        "outputId": "78e00ecf-4b16-4f56-9f37-d9dc26ed6350"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for filepath in pt_filepaths:\n",
        "    filename, ext = filepath[:-4], filepath[-4:]\n",
        "    shutil.move(filename+'.jpg', '/content/Dataset/images/test')\n",
        "    shutil.move(filename+'.txt', '/content/Dataset/labels/test')"
      ],
      "metadata": {
        "id": "5swapDS-Pw06"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(glob.glob('/content/Dataset/images/test/*')), len(glob.glob('/content/Dataset/labels/test/*'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsIhYZSRQgPr",
        "outputId": "b943702a-a780-4372-9cdd-65c30c60bab1"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(101, 101)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "yaml 파일 변경"
      ],
      "metadata": {
        "id": "3SYpn1e3S9WB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document = f'''\n",
        "path: /content/Dataset\n",
        "train: images/train\n",
        "val: images/test\n",
        "\n",
        "\n",
        "nc: {len(won_list)}\n",
        "names: {won_list}\n",
        "\n",
        "'''\n",
        "with open('/content/Dataset/money.yaml', 'w') as f:\n",
        "    f.write(document)"
      ],
      "metadata": {
        "id": "VmVc6h7XS_tM"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shutil.copytree('/content/Dataset/images/val', '/content/Dataset/images/test')\n",
        "# shutil.copytree('/content/Dataset/images/val', '/content/Dataset/labels/test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EnL0e_sCpq8Q",
        "outputId": "14ff2291-c75f-460e-cf84-b51e5aa07403"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Dataset/labels/test'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(glob.glob('/content/Dataset/images/val/*')) ,len(glob.glob('/content/Dataset/images/test/*'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fB6JsQsrTFs",
        "outputId": "a34fa317-d85c-4d46-f15a-66b29a078dc7"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1050, 1050)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd yolov5; python val.py\\\n",
        "    --data '/content/Dataset/money.yaml'\\\n",
        "    --weight '/content/drive/MyDrive/ktaivle_mp3th_2/train_money1/weights/best.pt'\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YqpAh_piSNI",
        "outputId": "614d79fe-669e-4c1f-d023-a208290ff38b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/content/Dataset/money.yaml, weights=['/content/drive/MyDrive/ktaivle_mp3th_2/train_money1/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v7.0-128-gb96f35c Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5m summary: 212 layers, 20881221 parameters, 0 gradients, 47.9 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Dataset/labels/test... 92 images, 0 backgrounds, 0 corrupt: 100% 92/92 [00:00<00:00, 4555.80it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Dataset/labels/test.cache\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:03<00:00,  1.01s/it]\n",
            "                   all         92        246      0.584      0.464      0.464      0.353\n",
            "                    10         92         25      0.475      0.434      0.434      0.372\n",
            "                    50         92         10      0.124        0.7      0.357      0.292\n",
            "                   100         92         52      0.544        0.5      0.566      0.468\n",
            "                   500         92         36          1          0      0.293      0.245\n",
            "                  1000         92         34      0.848      0.658      0.702      0.521\n",
            "                  5000         92         32      0.188      0.375      0.128     0.0955\n",
            "                 10000         92         35      0.696      0.514      0.547      0.401\n",
            "                 50000         92         22      0.795       0.53      0.686      0.429\n",
            "Speed: 0.4ms pre-process, 8.1ms inference, 5.2ms NMS per image at shape (32, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/val/exp3\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N49kf_u5r_qO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}